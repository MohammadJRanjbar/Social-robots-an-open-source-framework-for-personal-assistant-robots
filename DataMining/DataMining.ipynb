{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "def Markemotions(emotions):\r\n",
    "    df1 = pd.DataFrame({'Netural':emotions['neutral']})\r\n",
    "    df2 = pd.DataFrame({'sad':emotions['sad']})\r\n",
    "    df3 = pd.DataFrame({'happy':emotions['happy']})\r\n",
    "    df4 = pd.DataFrame({'angry':emotions['angry']})\r\n",
    "    df5 = pd.DataFrame({'disgust':emotions['disgust']})\r\n",
    "    df6 = pd.DataFrame({'surprise':emotions['surprise']})\r\n",
    "    df7 = pd.DataFrame({'fear':emotions['fear']})\r\n",
    "    df8= pd.concat([df1, df2,df3,df4,df5,df6,df7])\r\n",
    "    df8.to_csv(\"Emotions.csv\",index=False)\r\n",
    "    print(\"df is saved\")\r\n",
    "def plot_emotions(emotion_dict):\r\n",
    "    angry=[]\r\n",
    "    disgust=[]\r\n",
    "    fear=[]\r\n",
    "    happy=[]\r\n",
    "    sad=[]\r\n",
    "    surprise=[]\r\n",
    "    neutral=[]\r\n",
    "    for i in range(len(emotion_dict.keys())):\r\n",
    "        angry.append(list(emotion_dict.values())[i]['angry'])\r\n",
    "        disgust.append(list(emotion_dict.values())[i]['disgust'])\r\n",
    "        fear.append(list(emotion_dict.values())[i]['fear'])\r\n",
    "        happy.append(list(emotion_dict.values())[i]['happy'])\r\n",
    "        sad.append(list(emotion_dict.values())[i]['sad'])\r\n",
    "        surprise.append(list(emotion_dict.values())[i]['surprise'])\r\n",
    "        neutral.append(list(emotion_dict.values())[i]['neutral'])\r\n",
    "    #plt.scatter(list(emotion_dict.keys()), angry, color='red', marker='o' ,alpha=0.2, cmap='viridis')\r\n",
    "    #plt.scatter(list(emotion_dict.keys()), sad, color='blue', marker='o' ,alpha=0.2, cmap='viridis')\r\n",
    "\r\n",
    "    fig = plt.figure(figsize=(8, 5), dpi=80)\r\n",
    "    plt.bar(list(emotion_dict.keys()), neutral,color='teal',linestyle='dashed' , label='Neutral')\r\n",
    "    plt.bar(list(emotion_dict.keys()), happy,color='m',linestyle='dashed' , label='Happy')\r\n",
    "    plt.bar(list(emotion_dict.keys()), sad,color='blue',linestyle='dashed' , label='Sad')\r\n",
    "    plt.bar(list(emotion_dict.keys()), angry,color='red',linestyle='dashed' , label='Angry')\r\n",
    "    plt.bar(list(emotion_dict.keys()), disgust,color='g',linestyle='dashed' , label='Disgust')\r\n",
    "    plt.bar(list(emotion_dict.keys()), fear,color='black',linestyle='dashed' , label='Fear')\r\n",
    "    plt.bar(list(emotion_dict.keys()), surprise,color='y',linestyle='dashed' , label='Surprise')\r\n",
    "    plt.legend(loc='upper right',fontsize=10)\r\n",
    "    #plt\r\n",
    "    plt.savefig('Emotion_plot.png')\r\n",
    "    print(\"plot has been saved\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def plot_piechart(Commen_emotion):\r\n",
    "    my_dict = {i:Commen_emotion.count(i) for i in Commen_emotion}\r\n",
    "\r\n",
    "    colors = ['#99ff99','#ffcc99','#ff9999','blue','green','yellow','red','purple']\r\n",
    "    plt.pie([float(my_dict[v]) for v in my_dict],colors=colors, labels=[str(k) for k in my_dict], autopct='%1.1f%%', startangle=90)\r\n",
    "    plt.savefig('Pie_chart.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from PyQt5 import QtGui\r\n",
    "from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QVBoxLayout\r\n",
    "from PyQt5.QtGui import QPixmap\r\n",
    "import sys\r\n",
    "import cv2\r\n",
    "from PyQt5.QtCore import pyqtSignal, pyqtSlot, Qt, QThread\r\n",
    "import numpy as np\r\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QHBoxLayout, QVBoxLayout, QLabel,QSlider, QStyle, QSizePolicy, QFileDialog\r\n",
    "import sys\r\n",
    "from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent\r\n",
    "from PyQt5.QtMultimediaWidgets import QVideoWidget\r\n",
    "from PyQt5.QtGui import QIcon, QPalette\r\n",
    "from PyQt5.QtCore import Qt, QUrl\r\n",
    "import cv2\r\n",
    "from deepface import DeepFace\r\n",
    "from datetime import datetime,timedelta\r\n",
    "from statistics import mode\r\n",
    "import numpy as np\r\n",
    "global movie_name\r\n",
    "from PyQt5.QtGui import QPalette , QColor,QFont,QIcon ,QPixmap\r\n",
    "class VideoThread(QThread):\r\n",
    "    change_pixmap_signal = pyqtSignal(np.ndarray)\r\n",
    "\r\n",
    "    def run(self):\r\n",
    "        # capture from web cam\r\n",
    "        facecascade=cv2.CascadeClassifier(cv2.data.haarcascades+ \"haarcascade_frontalface_alt2.xml\")\r\n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\r\n",
    "        \r\n",
    "\r\n",
    "        frame_count=0\r\n",
    "        emotion_dict={}\r\n",
    "        Commen_emotion=[]\r\n",
    "\r\n",
    "        #ret=True\r\n",
    "        count_time=0\r\n",
    "        time=0\r\n",
    "        now=timedelta(seconds=time)\r\n",
    "        time_list=[]\r\n",
    "\r\n",
    "        empty_dict = {'neutral': [], 'happy': [],'sad': [], 'angry': [],'disgust': [], 'surprise': [], 'fear': []}\r\n",
    "        cap = cv2.VideoCapture(movie_name)\r\n",
    "        while True:\r\n",
    "            ret, frame = cap.read()\r\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\r\n",
    "            if ret:\r\n",
    "                frame = cv2.GaussianBlur(frame,(3,3),1)\r\n",
    "                gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\r\n",
    "                faces=facecascade.detectMultiScale(gray,1.5,4)\r\n",
    "                dominant_emotion=\"\"\r\n",
    "                dominant_emotion_Percent=0\r\n",
    "                frame_count=frame_count+1\r\n",
    "                time = float(frame_count)/fps\r\n",
    "                for (x,y,w,h) in faces:\r\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\r\n",
    "                    predication=DeepFace.analyze(frame[y:y+h,x:x+w],actions = ['emotion'],enforce_detection=False)\r\n",
    "                    emotion_dict[round(time*100)]=predication['emotion']\r\n",
    "                    \r\n",
    "                    Commen_emotion.append(predication['dominant_emotion'])\r\n",
    "\r\n",
    "                    cv2.putText(frame,str(predication['dominant_emotion'])+ \": \" + str(round(predication['emotion'][predication['dominant_emotion']],2)),(x,y-10),font,1,(0,255,0),2, cv2.LINE_AA)\r\n",
    "                    break\r\n",
    "                try:\r\n",
    "                    if(count_time>5):\r\n",
    "                        if(mode(Commen_emotion[-10:])!=mode(Commen_emotion[-20:-10])):\r\n",
    "                            second=timedelta(seconds=time)\r\n",
    "                            empty_dict[mode(Commen_emotion[-20:-10])].append(str(now)+\"-\"+str(second))\r\n",
    "                            #time_list.append([now,second,mode(Commen_emotion[-20:-10])])\r\n",
    "                            #print(mode(Commen_emotion[-10:]))\r\n",
    "                            #print(mode(Commen_emotion[-20:-10]))\r\n",
    "                            count_time=0\r\n",
    "                            #print(now,second)\r\n",
    "                            \r\n",
    "                            now=second\r\n",
    "                except Exception as e:\r\n",
    "                    #print(e)\r\n",
    "                    pass\r\n",
    "\r\n",
    "                count_time=count_time+1\r\n",
    "                self.change_pixmap_signal.emit(frame)\r\n",
    "            else:\r\n",
    "                empty_dict[mode(Commen_emotion[-10:])].append(str(now)+\"-\"+str(timedelta(seconds=time)))\r\n",
    "                Markemotions(empty_dict)\r\n",
    "                plot_emotions(emotion_dict)\r\n",
    "                plot_piechart(Commen_emotion)\r\n",
    "                break\r\n",
    "class App(QWidget):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        #self.setWindowTitle(\"PyQt5 Media Player\")\r\n",
    "        self.setGeometry(350, 100, 700, 500)\r\n",
    "        self.setWindowIcon(QIcon('FE.png'))\r\n",
    "        \r\n",
    "        self.setWindowTitle(\"Emotion Recognition\")\r\n",
    "        self.disply_width = 640\r\n",
    "        self.display_height = 480\r\n",
    "        # create the label that holds the image\r\n",
    "        self.image_label = QLabel(self)\r\n",
    "        self.image_label.resize(self.disply_width, self.display_height)\r\n",
    "        # create a text label\r\n",
    "        self.textLabel = QLabel('')\r\n",
    "\r\n",
    "        # create a vertical box layout and add the two labels\r\n",
    "        vbox = QVBoxLayout()\r\n",
    "        vbox.addWidget(self.image_label)\r\n",
    "        vbox.addWidget(self.textLabel)\r\n",
    "        # set the vbox layout as the widgets layout\r\n",
    "        self.setLayout(vbox)\r\n",
    "        \r\n",
    "        self.openBtn = QPushButton('Open Video')\r\n",
    "        self.openBtn.clicked.connect(self.open_file)\r\n",
    "        vbox.addWidget(self.openBtn)\r\n",
    "        # create the video capture thread\r\n",
    "        self.thread = VideoThread()\r\n",
    "        # connect its signal to the update_image slot\r\n",
    "        self.thread.change_pixmap_signal.connect(self.update_image)\r\n",
    "        # start the thread\r\n",
    "        \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    @pyqtSlot(np.ndarray)\r\n",
    "    def update_image(self, cv_img):\r\n",
    "        \"\"\"Updates the image_label with a new opencv image\"\"\"\r\n",
    "        qt_img = self.convert_cv_qt(cv_img)\r\n",
    "        self.image_label.setPixmap(qt_img)\r\n",
    "\r\n",
    "    def open_file(self):\r\n",
    "        global movie_name\r\n",
    "        movie_name , _ = QFileDialog.getOpenFileName(self, \"Open Video\")\r\n",
    "        self.thread.start()\r\n",
    "\r\n",
    "    def convert_cv_qt(self, cv_img):\r\n",
    "        \"\"\"Convert from an opencv image to QPixmap\"\"\"\r\n",
    "        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\r\n",
    "        h, w, ch = rgb_image.shape\r\n",
    "        bytes_per_line = ch * w\r\n",
    "        convert_to_Qt_format = QtGui.QImage(rgb_image.data, w, h, bytes_per_line, QtGui.QImage.Format_RGB888)\r\n",
    "        p = convert_to_Qt_format.scaled(self.disply_width, self.display_height, Qt.KeepAspectRatio)\r\n",
    "        return QPixmap.fromImage(p)\r\n",
    "    \r\n",
    "if __name__==\"__main__\":\r\n",
    "    app = QApplication(sys.argv)\r\n",
    "    app.setStyle(\"Fusion\")\r\n",
    "    palette = QPalette()\r\n",
    "    palette.setColor(QPalette.Window, QColor(53, 53, 53))\r\n",
    "    palette.setColor(QPalette.WindowText, QColor(255, 255, 255))\r\n",
    "    palette.setColor(QPalette.Base, QColor(25, 25, 25))\r\n",
    "    palette.setColor(QPalette.AlternateBase, QColor(53, 53, 53))\r\n",
    "    palette.setColor(QPalette.ToolTipBase, QColor(255, 255, 255))\r\n",
    "    palette.setColor(QPalette.ToolTipText, QColor(255, 255, 255))\r\n",
    "    palette.setColor(QPalette.Text, QColor(255, 255, 255))\r\n",
    "    palette.setColor(QPalette.Button, QColor(53, 53, 53))\r\n",
    "    palette.setColor(QPalette.ButtonText, QColor(255, 255, 255))\r\n",
    "    palette.setColor(QPalette.BrightText, QColor(255, 0, 0))\r\n",
    "    palette.setColor(QPalette.Link, QColor(42, 130, 218))\r\n",
    "    palette.setColor(QPalette.Highlight, QColor(42, 130, 218))\r\n",
    "    palette.setColor(QPalette.HighlightedText, QColor(0, 0, 0))\r\n",
    "    app.setPalette(palette)\r\n",
    "    a = App()\r\n",
    "    a.show()\r\n",
    "    sys.exit(app.exec_())"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "0",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}